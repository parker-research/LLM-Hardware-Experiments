- configured_llm_name: "mock_llm_passes_tests"
  llm_class: "MockLlm"
  is_stable: true
  response_delay_seconds: 0.0001
  does_respond_to_test_queries: true

- configured_llm_name: "mock_llm_fails_tests"
  llm_class: "MockLlm"
  is_stable: true
  response_delay_seconds: 0.0001
  does_respond_to_test_queries: false


- configured_llm_name: "ollama_llama2_7b"
  llm_class: "OllamaLlm"
  model_name: "llama2:7b"
  

- configured_llm_name: "ollama_llama2_7b_stable"
  llm_class: "OllamaLlm"
  model_name: "llama2:7b"
  is_stable: true # indicates deterministic responses
  option_seed: 192910
  option_temperature: 0 # sets no randomness in the response


- configured_llm_name: "ollama_llama2_13b"
  llm_class: "OllamaLlm"
  model_name: "llama2:13b"

- configured_llm_name: "ollama_llama3_8b"
  llm_class: "OllamaLlm"
  model_name: "llama3:8b"

- configured_llm_name: "ollama_codellama_7b"
  llm_class: "OllamaLlm"
  model_name: "codellama:7b"

- configured_llm_name: "ollama_codellama_13b"
  llm_class: "OllamaLlm"
  model_name: "codellama:13b"

- configured_llm_name: "ollama_codellama_34b"
  llm_class: "OllamaLlm"
  model_name: "codellama:34b"

- configured_llm_name: "chatgpt-3.5"
  llm_class: "ChatGptLlm"
  model_name: "gpt-3.5-turbo"
  # option_seed: 192910
  # option_temperature: 0 # sets no randomness in the response (but doesn't really work on GPT)
